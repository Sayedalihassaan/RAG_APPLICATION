# ğŸ¤– RAG-based Document QA App using LangChain & Gemini

This project is a **Retrieval-Augmented Generation (RAG)** application built with **Streamlit**, **LangChain**, and **Google's Gemini API**. It allows users to upload documents (PDF, DOCX, or TXT), process them into chunks, embed them using **Google Generative AI Embeddings**, and interact with the content via conversational or standard Q&A.

## ğŸš€ Features

- ğŸ“„ Upload and process `.pdf`, `.docx`, and `.txt` files.
- ğŸ” Ask questions directly from your documents.
- ğŸ§  Optional conversational memory for follow-up Q&A.
- âš¡ Uses **FAISS** for fast vector-based retrieval.
- ğŸŒ Powered by **Google Gemini** (via `langchain-google-genai`).
- ğŸ› ï¸ Full configuration from the Streamlit sidebar.

---

## ğŸ“¸ Demo

![App Screenshot](./assets/download.png)

---

## ğŸ§° Tech Stack

- [LangChain](https://www.langchain.com/)
- [Streamlit](https://streamlit.io/)
- [FAISS (Facebook AI Similarity Search)](https://github.com/facebookresearch/faiss)
- [Google Gemini + Embeddings](https://makersuite.google.com/app)
- [dotenv](https://pypi.org/project/python-dotenv/)

---

## ğŸ“‚ Project Structure

```

.
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ download.png          # Optional logo or image
â”œâ”€â”€ .env                      # Store your Google API key securely
â”œâ”€â”€ APP.py                   # Main Streamlit application
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                 # You're reading it!
â””â”€â”€ create\_structure.py       # Script to initialize project files

````

---

## ğŸ”§ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/rag-doc-qa-app.git
cd rag-doc-qa-app
````

### 2. Create virtual environment (optional but recommended)

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Add your API key

Create a `.env` file and add:

```env
GOOGLE_API_KEY=your_google_gemini_api_key_here
```

### 5. Run the app

```bash
streamlit run APP.py
```

---

## ğŸ“ Process Flow

1. Upload a document (PDF, DOCX, or TXT).
2. The document is chunked using `RecursiveCharacterTextSplitter`.
3. Chunks are embedded using **Google Generative AI Embeddings**.
4. Vectors are stored in a local **FAISS** index.
5. User inputs questions in the UI.
6. The app retrieves relevant chunks and sends them to **Gemini LLM** for response.
7. Optionally use memory for contextual follow-up questions.

---

## ğŸ›¡ï¸ API Note

This project uses **Google Gemini (Generative AI)** via `langchain-google-genai`. You can obtain an API key from [Google AI Studio](https://makersuite.google.com/app) and manage limits from your Google Cloud Console.

---

## ğŸ§ª Example Use Cases

* Reading and querying long research papers
* Company policy document Q\&A
* Chat-style exploration of legal or technical documents

---

## ğŸ“Œ TODO

* âœ… Multi-format document ingestion
* âœ… Embedding with Gemini
* âœ… FAISS vector storage
* âœ… Memory-enabled chat
* ğŸ”œ PDF preview
* ğŸ”œ File management dashboard
* ğŸ”œ Export chat logs

---

## ğŸ‘¨â€ğŸ’» Author

**Sayed Ali**
AI Engineer | Python Enthusiast | Document Intelligence
[LinkedIn](https://www.linkedin.com/in/sayed-ali-482668262/) â€¢ [GitHub](https://github.com/Sayedalihassaan)

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ™Œ Acknowledgements

* [LangChain](https://www.langchain.com/)
* [Google Gemini API](https://ai.google.dev/)
* [FAISS](https://github.com/facebookresearch/faiss)
* [Streamlit](https://streamlit.io/)

```
